{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45240694-6c45-4e77-8761-256af0d7fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 29)\n",
      "(820,)\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. Carregando data.csv\n",
    "data = pd.read_csv('Data_CSV/data_alzheimer.csv')\n",
    "\n",
    "# Breast_cancer_data_Suwal_2018.csv\n",
    "# Data_Alzheimer_Diagnosis.csv\n",
    "# data_Breast_Cancer_Wisconsin.csv\n",
    "# data_Mammography.csv\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "data_filled = imputer.fit_transform(data)\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "data = data_filled\n",
    "\n",
    "# Supondo que a última coluna seja a classe\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Converta para DataFrame para facilitar a seleção de características\n",
    "# df = pd.DataFrame(X)\n",
    "# corr_matrix = df.corr().abs()\n",
    "\n",
    "# Encontre características altamente correlacionadas\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]  # Limite\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Remova as mesmas características de ambos os conjuntos (treinamento e teste)\n",
    "# X_train_reduced = X_train.drop(to_drop, axis=1)\n",
    "# X_test_reduced = X_test.drop(to_drop, axis=1)\n",
    "\n",
    "# print(f\"Shape of X_train_reduced: {X_train_reduced.shape}\")\n",
    "# print(f\"Shape of X_test_reduced: {X_test_reduced.shape}\")\n",
    "# print(f\"Shape of y_train: {y_train.shape}\")\n",
    "# print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7757bd78-fcff-43d0-a9ef-6f1c537262a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# # Normalizar os dados\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# scaler = StandardScaler()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# X_train_scaled = scaler.fit_transform(X_train)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# X_test_scaled = scaler.transform(X_test)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#PCA analysis\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m)  \u001b[38;5;66;03m# Preserve 95% of the variance\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train_scaled\u001b[49m)\n\u001b[0;32m     14\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test_scaled)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Inicializar o Bayesiano\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Adicione essa linha para importar StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# # Normalizar os dados\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#PCA analysis\n",
    "# pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "# Inicializar o Bayesiano\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train_scaled, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Inicializar o LDA com shrinkage para reduzir a colinearidade\n",
    "lda_classifier = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "lda_classifier.fit(X_train_scaled, y_train)\n",
    "lda_predictions = lda_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Quadrado\n",
    "qda_classifier = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
    "qda_classifier.fit(X_train_scaled, y_train)\n",
    "qda_predictions = qda_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46213d51-0be9-44d1-a983-be24ec97aab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcurácia geral: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(classification_report(y_true, y_pred))\n\u001b[1;32m---> 18\u001b[0m evaluate_with_confusion_matrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m'\u001b[39m,y_test, \u001b[43mnb_predictions\u001b[49m)\n\u001b[0;32m     19\u001b[0m evaluate_with_confusion_matrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Discriminant Analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test, lda_predictions)\n\u001b[0;32m     20\u001b[0m evaluate_with_confusion_matrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuadratic Discriminant Analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test, qda_predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nb_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Avaliação dos modelos\n",
    "#Função para avaliar cada modelo\n",
    "\n",
    "def evaluate_with_confusion_matrix(name, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'\\n{name} Classifier - Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    # Acurácia por classe\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis = 1)\n",
    "        print(f'Acurácia por classe:{class_accuracies}')\n",
    "\n",
    "    # Acurácia geral\n",
    "        overall_accuracy = cm.diagonal().sum() / cm.sum()\n",
    "        print(f'Acurácia geral: {overall_accuracy:.4f}')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_with_confusion_matrix('Naive Bayes',y_test, nb_predictions)\n",
    "evaluate_with_confusion_matrix('Linear Discriminant Analysis', y_test, lda_predictions)\n",
    "evaluate_with_confusion_matrix('Quadratic Discriminant Analysis', y_test, qda_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f6426a-d051-49d2-832a-3dc96acd8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.93292683 0.92073171 0.93902439 0.93292683 0.93902439 0.95121951\n",
      " 0.93292683 0.95731707 0.95121951 0.95121951 0.92682927 0.9695122\n",
      " 0.93902439 0.93902439 0.93292683 0.96341463 0.96341463 0.9695122\n",
      " 0.92682927 0.94512195 0.92682927 0.92682927 0.93292683 0.96341463\n",
      " 0.95731707 0.93292683 0.93902439 0.96341463 0.93902439 0.96341463\n",
      " 0.95121951 0.94512195 0.93292683 0.95121951 0.92073171 0.92073171\n",
      " 0.92073171 0.95731707 0.93902439 0.96341463 0.93902439 0.9695122\n",
      " 0.94512195 0.94512195 0.94512195 0.95121951 0.95731707 0.93902439\n",
      " 0.95731707 0.93902439 0.93292683 0.93902439 0.94512195 0.9695122\n",
      " 0.9695122  0.94512195 0.95731707 0.93902439 0.95121951 0.94512195\n",
      " 0.96341463 0.95121951 0.94512195 0.94512195 0.93902439 0.93902439\n",
      " 0.96341463 0.93902439 0.95121951 0.91463415 0.9695122  0.94512195\n",
      " 0.92073171 0.93902439 0.91463415 0.91463415 0.94512195 0.94512195\n",
      " 0.94512195 0.95731707 0.96341463 0.93902439 0.96341463 0.97560976\n",
      " 0.93902439 0.97560976 0.95121951 0.95731707 0.95121951 0.92073171\n",
      " 0.93902439 0.94512195 0.9695122  0.94512195 0.9695122  0.95731707\n",
      " 0.93292683 0.92682927 0.95731707 0.93292683]\n",
      "Média da acurácia: 0.9457317073170731\n",
      "Desvio padrão da acurácia: 0.014848531294982807\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.96341463 0.97560976 0.91463415 0.96341463 0.93902439 0.95121951\n",
      " 0.97560976 0.8902439  0.96341463 0.95121951 0.95121951 0.91463415\n",
      " 0.96341463 0.96341463 0.97560976 0.90243902 0.93902439 0.92682927\n",
      " 0.95121951 0.92682927 0.87804878 0.96341463 0.8902439  0.95121951\n",
      " 0.93902439 0.95121951 0.93902439 0.95121951 0.92682927 0.95121951\n",
      " 0.92682927 0.92682927 0.95121951 0.95121951 0.93902439 0.97560976\n",
      " 0.8902439  0.96341463 0.93902439 0.95121951 0.92682927 0.95121951\n",
      " 0.95121951 0.95121951 0.96341463 0.92682927 0.91463415 0.92682927\n",
      " 0.86585366 0.96341463 0.95121951 0.97560976 0.98780488 0.97560976\n",
      " 0.92682927 0.93902439 0.92682927 0.91463415 0.90243902 0.92682927\n",
      " 0.93902439 0.92682927 0.96341463 0.92682927 0.98780488 0.96341463\n",
      " 0.93902439 0.96341463 0.98780488 0.95121951 0.95121951 0.93902439\n",
      " 0.91463415 0.95121951 0.95121951 0.96341463 0.95121951 0.93902439\n",
      " 0.95121951 0.97560976 0.96341463 0.95121951 0.86585366 0.97560976\n",
      " 0.92682927 0.90243902 0.95121951 0.91463415 0.97560976 0.93902439\n",
      " 0.90243902 0.98780488 0.95121951 0.95121951 0.97560976 0.91463415\n",
      " 0.95121951 0.97560976 0.98780488 0.95121951]\n",
      "Média da acurácia: 0.943780487804878\n",
      "Desvio padrão da acurácia: 0.026432487266719592\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.91463415 0.8902439  0.8902439  0.90243902 0.91463415 0.91463415\n",
      " 0.86585366 0.87804878 0.95121951 0.91463415]\n",
      "Média da acurácia: 0.9036585365853658\n",
      "Desvio padrão da acurácia: 0.02278236791740171\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "df = data\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 100  # Número de iterações\n",
    "test_size = 0.2  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 100  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcf66a3d-4da4-44f3-97b5-8528ccd006e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Mean: 50.17097903302651\n",
      "Means of New Bins: [np.float64(53.05168565353928), np.float64(67.05060892671652), np.float64(52.76203603529248), np.float64(34.12083593020547), np.float64(38.784432125144264), np.float64(46.14795321402105), np.float64(37.69138521756676), np.float64(71.75889516172624)]\n",
      "Overall New Mean: 50.17097903302651\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
