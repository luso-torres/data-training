{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45240694-6c45-4e77-8761-256af0d7fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 0)\n",
      "(820,)\n",
      "Shape of X_train_reduced: (656, 0)\n",
      "Shape of X_test_reduced: (164, 0)\n",
      "Shape of y_train: (656,)\n",
      "Shape of y_test: (164,)\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. Carregando data.csv\n",
    "data = pd.read_csv('Data_CSV/Data_Alzheimer_Diagnosis.csv')\n",
    "\n",
    "# Breast_cancer_data_Suwal_2018.csv\n",
    "# Data_Alzheimer_Diagnosis.csv\n",
    "# data_Breast_Cancer_Wisconsin.csv\n",
    "# data_Mammography.csv\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "data_filled = imputer.fit_transform(data)\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "data = data_filled\n",
    "\n",
    "# Supondo que a última coluna seja a classe\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Converta para DataFrame para facilitar a seleção de características\n",
    "df = pd.DataFrame(X)\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Encontre características altamente correlacionadas\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]  # Limite\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Remova as mesmas características de ambos os conjuntos (treinamento e teste)\n",
    "X_train_reduced = X_train.drop(to_drop, axis=1)\n",
    "X_test_reduced = X_test.drop(to_drop, axis=1)\n",
    "\n",
    "print(f\"Shape of X_train_reduced: {X_train_reduced.shape}\")\n",
    "print(f\"Shape of X_test_reduced: {X_test_reduced.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7757bd78-fcff-43d0-a9ef-6f1c537262a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Normalizar os dados\u001b[39;00m\n\u001b[0;32m      7\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 8\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#PCA analysis\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    904\u001b[0m             (\n\u001b[0;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    914\u001b[0m         )\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:930\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    929\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 930\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    938\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    927\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    928\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    929\u001b[0m )\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 931\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[0;32m    934\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Adicione essa linha para importar StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#PCA analysis\n",
    "pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "# Inicializar o Bayesiano\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train_scaled, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Inicializar o LDA com shrinkage para reduzir a colinearidade\n",
    "lda_classifier = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "lda_classifier.fit(X_train_scaled, y_train)\n",
    "lda_predictions = lda_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Quadrado\n",
    "qda_classifier = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
    "qda_classifier.fit(X_train_scaled, y_train)\n",
    "qda_predictions = qda_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46213d51-0be9-44d1-a983-be24ec97aab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier - Confusion Matrix:\n",
      "[[88  7]\n",
      " [ 2 43]]\n",
      "Acurácia por classe:[0.92631579 0.95555556]\n",
      "Acurácia geral: 0.9357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95        95\n",
      "         1.0       0.86      0.96      0.91        45\n",
      "\n",
      "    accuracy                           0.94       140\n",
      "   macro avg       0.92      0.94      0.93       140\n",
      "weighted avg       0.94      0.94      0.94       140\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis Classifier - Confusion Matrix:\n",
      "[[94  1]\n",
      " [ 3 42]]\n",
      "Acurácia por classe:[0.98947368 0.93333333]\n",
      "Acurácia geral: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98        95\n",
      "         1.0       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.96      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "\n",
      "Quadratic Discriminant Analysis Classifier - Confusion Matrix:\n",
      "[[91  4]\n",
      " [ 2 43]]\n",
      "Acurácia por classe:[0.95789474 0.95555556]\n",
      "Acurácia geral: 0.9571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97        95\n",
      "         1.0       0.91      0.96      0.93        45\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.95      0.96      0.95       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Avaliação dos modelos\n",
    "#Função para avaliar cada modelo\n",
    "\n",
    "def evaluate_with_confusion_matrix(name, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'\\n{name} Classifier - Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    # Acurácia por classe\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis = 1)\n",
    "        print(f'Acurácia por classe:{class_accuracies}')\n",
    "\n",
    "    # Acurácia geral\n",
    "        overall_accuracy = cm.diagonal().sum() / cm.sum()\n",
    "        print(f'Acurácia geral: {overall_accuracy:.4f}')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_with_confusion_matrix('Naive Bayes',y_test, nb_predictions)\n",
    "evaluate_with_confusion_matrix('Linear Discriminant Analysis', y_test, lda_predictions)\n",
    "evaluate_with_confusion_matrix('Quadratic Discriminant Analysis', y_test, qda_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57f6426a-d051-49d2-832a-3dc96acd8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.97857143 0.96428571 0.97142857 0.98571429 0.93571429 0.95714286\n",
      " 0.96428571 0.97142857 0.96428571 0.96428571 0.97142857 0.94285714\n",
      " 0.92857143 0.96428571 0.96428571 0.95714286 0.95       0.97857143\n",
      " 0.91428571 0.94285714 0.97142857 0.98571429 0.95       0.95714286\n",
      " 0.96428571 0.95       0.93571429 0.95       0.94285714 0.97142857\n",
      " 0.97142857 0.96428571 0.97857143 0.95714286 0.9        0.97142857\n",
      " 0.96428571 0.95714286 0.94285714 0.97142857 0.94285714 0.99285714\n",
      " 0.97142857 0.97142857 0.97142857 0.97857143 0.93571429 0.95714286\n",
      " 0.97857143 0.95       0.95       0.96428571 0.97857143 0.93571429\n",
      " 0.96428571 0.97857143 0.95714286 0.96428571 0.95714286 0.96428571\n",
      " 0.92857143 0.94285714 0.92857143 0.96428571 0.95       0.97142857\n",
      " 0.92857143 0.97857143 0.96428571 0.99285714 0.92857143 0.97142857\n",
      " 0.95714286 0.93571429 0.97857143 0.98571429 0.95       0.96428571\n",
      " 0.97142857 0.97142857 0.97142857 0.96428571 0.95714286 0.97857143\n",
      " 0.95714286 0.93571429 0.97857143 0.94285714 0.93571429 0.93571429\n",
      " 0.97857143 0.94285714 0.97857143 0.98571429 0.92857143 0.96428571\n",
      " 0.97142857 0.92142857 0.97142857 0.96428571]\n",
      "Média da acurácia: 0.9592142857142858\n",
      "Desvio padrão da acurácia: 0.01816295287509322\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.94285714 0.91428571 0.95714286 0.94285714 0.95714286 0.95714286\n",
      " 0.94285714 0.91428571 0.95714286 0.97142857 0.94285714 0.94285714\n",
      " 0.97142857 0.97142857 0.92857143 0.88571429 0.95714286 0.97142857\n",
      " 0.98571429 0.97142857 0.94285714 0.97142857 0.95714286 0.94285714\n",
      " 0.97142857 0.95714286 0.97142857 0.97142857 0.92857143 0.95714286\n",
      " 1.         0.97142857 0.97142857 1.         1.         0.91428571\n",
      " 0.91428571 0.98571429 0.95714286 0.94285714 0.94285714 0.98571429\n",
      " 0.95714286 0.98571429 0.97142857 0.97142857 0.97142857 0.9\n",
      " 0.97142857 0.97142857 0.98571429 0.95714286 0.94285714 0.92857143\n",
      " 0.98571429 0.94285714 0.92857143 0.95714286 0.97142857 0.98571429\n",
      " 0.95714286 0.95714286 0.97142857 0.98571429 0.94285714 0.97142857\n",
      " 0.98571429 0.95714286 0.95714286 0.98571429 0.94285714 0.91428571\n",
      " 0.94285714 0.95714286 0.92857143 0.92857143 0.95714286 0.98571429\n",
      " 1.         0.95714286 0.98571429 0.94285714 0.95714286 0.97142857\n",
      " 0.94285714 0.92857143 0.91428571 0.95714286 0.94285714 0.92857143\n",
      " 0.95714286 0.91428571 0.94285714 0.95714286 0.92857143 0.98571429\n",
      " 0.92857143 0.97142857 0.92857143 0.95714286]\n",
      "Média da acurácia: 0.9555714285714286\n",
      "Desvio padrão da acurácia: 0.02363800122770148\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.98571429 0.97142857 0.94285714 0.97142857 0.95714286 0.98571429\n",
      " 0.95714286 0.94285714 0.97142857 0.97142857 0.97142857 0.95714286\n",
      " 0.97142857 0.95714286 0.98571429 0.95714286 0.92857143 0.92857143\n",
      " 0.97142857 0.95714286 0.91428571 0.95714286 1.         0.94285714\n",
      " 0.94285714 0.94285714 0.91428571 0.94285714 0.98571429 0.97142857\n",
      " 0.97142857 0.92857143 0.95714286 0.91428571 0.95714286 0.98571429\n",
      " 0.95714286 1.         0.98571429 0.92857143 0.92857143 0.97142857\n",
      " 0.97142857 0.97142857 0.98571429 0.97142857 0.94285714 0.97142857\n",
      " 0.95714286 0.98571429 0.97142857 0.95714286 0.95714286 0.94285714\n",
      " 0.97142857 0.95714286 0.94285714 0.91428571 0.95714286 0.98571429\n",
      " 0.95714286 0.95714286 0.9        0.97142857 0.92857143 0.98571429\n",
      " 0.97142857 0.95714286 0.95714286 0.94285714 0.92857143 0.98571429\n",
      " 0.95714286 0.95714286 0.91428571 0.97142857 0.98571429 0.98571429\n",
      " 0.95714286 0.98571429 0.9        0.98571429 0.95714286 0.98571429\n",
      " 0.92857143 0.94285714 0.9        0.92857143 0.98571429 0.95714286\n",
      " 0.97142857 0.92857143 0.97142857 0.98571429 0.98571429 0.97142857\n",
      " 0.95714286 0.92857143 0.95714286 0.97142857]\n",
      "Média da acurácia: 0.9581428571428572\n",
      "Desvio padrão da acurácia: 0.02323394771730824\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "df = data\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 100  # Número de iterações\n",
    "test_size = 0.2  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 100  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 100  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
