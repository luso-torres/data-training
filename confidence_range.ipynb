{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a812eeab-1bf8-47ad-9df1-700234739296",
   "metadata": {},
   "source": [
    "# Finding interval Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadf9c23-b672-43f1-b71c-70c07ff48c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 0)\n",
      "(0, 820)\n",
      "Total positive cases in the dataset: 592\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. Carregando data.csv\n",
    "\n",
    "data = pd.read_csv('Data_CSV/Data_Alzheimer_Diagnosis.csv')\n",
    "# Breast_cancer_data_Suwal_2018.csv\n",
    "# Data_Alzheimer_Diagnosis.csv\n",
    "# data_Breast_Cancer_Wisconsin.csv\n",
    "# data_Mammography.csv\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "data_filled = imputer.fit_transform(data)\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "data = data_filled\n",
    "\n",
    "# Supondo que a última coluna seja a classe\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y[len(y)==-1].shape)\n",
    "\n",
    "# Converta para DataFrame para facilitar a seleção de características\n",
    "# df = pd.DataFrame(X)\n",
    "# corr_matrix = df.corr().abs()\n",
    "\n",
    "# Encontre características altamente correlacionadas\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]  # Limite\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Remova as mesmas características de ambos os conjuntos (treinamento e teste)\n",
    "# X_train_reduced = X_train.drop(to_drop, axis=1)\n",
    "# X_test_reduced = X_test.drop(to_drop, axis=1)\n",
    "\n",
    "# print(f\"Shape of X_train_reduced: {X_train_reduced.shape}\")\n",
    "# print(f\"Shape of X_test_reduced: {X_test_reduced.shape}\")\n",
    "# print(f\"Shape of y_train: {y_train.shape}\")\n",
    "# print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Total positive cases in the dataset: {sum(y == 1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a10fd46b-4bee-43da-876f-5bc01297a6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases in the training set: 537\n",
      "Positive cases in the test set: 55\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(738, 0)) while a minimum of 1 is required by GaussianNB.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Inicializar o Bayesiano\u001b[39;00m\n\u001b[0;32m     18\u001b[0m nb_classifier \u001b[38;5;241m=\u001b[39m GaussianNB()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mnb_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m nb_predictions \u001b[38;5;241m=\u001b[39m nb_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Inicializar o LDA com shrinkage para reduzir a colinearidade\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\naive_bayes.py:266\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m y \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\naive_bayes.py:426\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    425\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[1;32m--> 426\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1139\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m-> 1139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1142\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m   1143\u001b[0m         )\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_non_negative:\n\u001b[0;32m   1146\u001b[0m     whom \u001b[38;5;241m=\u001b[39m input_name\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(738, 0)) while a minimum of 1 is required by GaussianNB."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Adicione essa linha para importar StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# # Normalizar os dados\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# #PCA analysis\n",
    "# pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "print(f\"Positive cases in the training set: {sum(y_train == 1)}\")\n",
    "print(f\"Positive cases in the test set: {sum(y_test == 1)}\")\n",
    "# Inicializar o Bayesiano\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "\n",
    "# Inicializar o LDA com shrinkage para reduzir a colinearidade\n",
    "lda_classifier = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "lda_predictions = lda_classifier.predict(X_test)\n",
    "\n",
    "# Quadrado\n",
    "qda_classifier = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
    "qda_classifier.fit(X_train, y_train)\n",
    "qda_predictions = qda_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42242500-3173-48b9-a0ec-9a7eac90d612",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcurácia geral: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(classification_report(y_true, y_pred))\n\u001b[1;32m---> 15\u001b[0m evaluate_with_confusion_matrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m'\u001b[39m,y_test, \u001b[43mnb_predictions\u001b[49m)\n\u001b[0;32m     16\u001b[0m evaluate_with_confusion_matrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Discriminant Analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test, lda_predictions)\n\u001b[0;32m     17\u001b[0m evaluate_with_confusion_matrix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuadratic Discriminant Analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test, qda_predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nb_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_with_confusion_matrix(name, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'\\n{name} Classifier - Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    # Acurácia por classe\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis = 1)\n",
    "        print(f'Acurácia por classe:{class_accuracies}')\n",
    "\n",
    "    # Acurácia geral\n",
    "        overall_accuracy = cm.diagonal().sum() / cm.sum()\n",
    "        print(f'Acurácia geral: {overall_accuracy:.4f}')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_with_confusion_matrix('Naive Bayes',y_test, nb_predictions)\n",
    "evaluate_with_confusion_matrix('Linear Discriminant Analysis', y_test, lda_predictions)\n",
    "evaluate_with_confusion_matrix('Quadratic Discriminant Analysis', y_test, qda_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4dd7f01-0405-4002-bb3c-4063cd4efa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.97587131 0.97944593 0.97944593 0.97676497 0.974084   0.98033959\n",
      " 0.97229669 0.98391421 0.96782842 0.97587131]\n",
      "Média da acurácia: 0.9765862377122432\n",
      "Desvio padrão da acurácia: 0.00431923001737072\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.97676497 0.97319035 0.98302055 0.98123324 0.97229669 0.98302055\n",
      " 0.97765862 0.97855228 0.97944593 0.97497766]\n",
      "Média da acurácia: 0.9780160857908846\n",
      "Desvio padrão da acurácia: 0.003601330058911509\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.95352994 0.96336014 0.95084897 0.9562109  0.95889187 0.94906166\n",
      " 0.95799821 0.95263628 0.96336014 0.95889187]\n",
      "Média da acurácia: 0.9564789991063452\n",
      "Desvio padrão da acurácia: 0.00467869172929703\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "550247ba-fc13-4bfc-b9af-f26b98c12cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.95121951 0.96341463 0.93902439 0.95121951 0.96341463 0.95121951\n",
      " 0.95121951 1.         0.93902439 0.90243902]\n",
      "Média da acurácia: 0.9512195121951219\n",
      "Desvio padrão da acurácia: 0.023138617025622282\n",
      "Limites: 95  0.9058678228249022 0.9965712015653416\n",
      "Limites 99,7:  0.881803661118255 1.0206353632719887\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.95121951 0.96341463 0.95121951 0.92682927 0.8902439  0.98780488\n",
      " 0.95121951 0.95121951 0.90243902 0.95121951]\n",
      "Média da acurácia: 0.9426829268292682\n",
      "Desvio padrão da acurácia: 0.027296377177560213\n",
      "Limites: 95  0.8891820275612502 0.9961838260972863\n",
      "Limites 99,7:  0.8607937952965876 1.0245720583619489\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.90243902 0.96341463 0.92682927 0.93902439 0.93902439 0.90243902\n",
      " 0.93902439 0.97560976 0.8902439  0.91463415]\n",
      "Média da acurácia: 0.9292682926829267\n",
      "Desvio padrão da acurácia: 0.026041654273247075\n",
      "Limites: 95  0.8782266503073624 0.980309935058491\n",
      "Limites 99,7:  0.8511433298631854 1.007393255502668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('Data_CSV/Breast_cancer_data_Suwal_2018.csv')\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print(\"Limites: 95 \",x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print(\"Limites 99,7: \",x_l,x_h)\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f1df25f-0c85-438f-9a06-177ba40a54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.93902439 0.93902439 0.96341463 0.96341463 0.92682927 0.8902439\n",
      " 0.97560976 0.95121951 0.96341463 0.98780488]\n",
      "Média da acurácia: 0.95\n",
      "Desvio padrão da acurácia: 0.026410253448424032\n",
      "Limites: 95  0.8982359032410888 1.001764096758911\n",
      "Limites 99,7:  0.8707692396547279 1.0292307603452722\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.97560976 0.96341463 0.95121951 0.95121951 0.92682927 0.95121951\n",
      " 0.93902439 0.92682927 0.97560976 0.92682927]\n",
      "Média da acurácia: 0.9487804878048781\n",
      "Desvio padrão da acurácia: 0.01792309567890128\n",
      "Limites: 95  0.9136512202742316 0.9839097553355246\n",
      "Limites 99,7:  0.8950112007681743 1.002549774841582\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.91463415 0.95121951 0.92682927 0.90243902 0.92682927 0.91463415\n",
      " 0.91463415 0.8902439  0.92682927 0.92682927]\n",
      "Média da acurácia: 0.9195121951219514\n",
      "Desvio padrão da acurácia: 0.015617376188860598\n",
      "Limites: 95  0.8889021377917846 0.9501222524521181\n",
      "Limites 99,7:  0.8726600665553695 0.9663643236885332\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('Data_CSV/data_alzheimer.csv')\n",
    "df =data\n",
    "\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bf613a4-b50e-4b71-82db-db8b8e2e1ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.95714286 0.98571429 0.97142857 1.         0.98571429 0.97142857\n",
      " 0.94285714 0.98571429 0.98571429 0.94285714]\n",
      "Média da acurácia: 0.972857142857143\n",
      "Desvio padrão da acurácia: 0.018571428571428586\n",
      "Limites: 95  0.936457142857143 1.009257142857143\n",
      "Limites 99,7:  0.9171428571428573 1.0285714285714287\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.98571429 0.95714286 0.94285714 0.94285714 0.95714286 1.\n",
      " 0.97142857 0.9        1.         0.98571429]\n",
      "Média da acurácia: 0.9642857142857144\n",
      "Desvio padrão da acurácia: 0.02945075446869758\n",
      "Limites: 95  0.9065622355270672 1.0220091930443618\n",
      "Limites 99,7:  0.8759334508796217 1.0526379776918071\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.91428571 0.95714286 0.97142857 0.97142857 0.95714286 0.97142857\n",
      " 0.97142857 0.95714286 0.95714286 0.94285714]\n",
      "Média da acurácia: 0.9571428571428571\n",
      "Desvio padrão da acurácia: 0.01690308509457034\n",
      "Limites: 95  0.9240128103574992 0.990272903928215\n",
      "Limites 99,7:  0.906433601859146 1.007852112426568\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('Data_CSV/data_Breast_Cancer_Wisconsin.csv')\n",
    "df = data\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "data_filled = imputer.fit_transform(data)\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "df = data_filled\n",
    "\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8359de4-e887-4cb5-9f74-7f3e86e3ed54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.97229669 0.97229669 0.974084   0.97676497 0.97855228 0.97319035\n",
      " 0.9821269  0.97944593 0.97587131 0.97765862]\n",
      "Média da acurácia: 0.9762287756925827\n",
      "Desvio padrão da acurácia: 0.0031265157613111715\n",
      "Limites: 95  0.9701008048004128 0.9823567465847526\n",
      "Limites 99,7:  0.9668492284086492 0.9856083229765162\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.97855228 0.97140304 0.97587131 0.97497766 0.97944593 0.97497766\n",
      " 0.97229669 0.97765862 0.97050938 0.97676497]\n",
      "Média da acurácia: 0.9752457551385165\n",
      "Desvio padrão da acurácia: 0.002883336158159376\n",
      "Limites: 95  0.9695944162685242 0.9808970940085089\n",
      "Limites 99,7:  0.9665957466640384 0.9838957636129947\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.95531725 0.96157283 0.94548704 0.94727435 0.9562109  0.95174263\n",
      " 0.95978552 0.95531725 0.95442359 0.96067918]\n",
      "Média da acurácia: 0.9547810545129579\n",
      "Desvio padrão da acurácia: 0.0051055788586544075\n",
      "Limites: 95  0.9447741199499953 0.9647879890759206\n",
      "Limites 99,7:  0.9394643179369947 0.9700977910889211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "df = pd.read_csv('Data_CSV/data_Mammography.csv')\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print('Limites: 95 ',x_l,x_h)\n",
    "x_l = scores.mean() - 3*scores.std()\n",
    "x_h = scores.mean() + 3*scores.std()\n",
    "\n",
    "print('Limites 99,7: ',x_l,x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9d04af1-35e1-48dc-8fdf-507f40c85041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9451220169801913 0.96908709830131\n"
     ]
    }
   ],
   "source": [
    "x_l = scores.mean() - 1.96*scores.std()\n",
    "x_h = scores.mean() + 1.96*scores.std()\n",
    "\n",
    "print(x_l,x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f6fc6dd-462d-4256-94f5-6e0349d68dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47e3b2cb-3835-47c3-9d9f-f78cdbe00bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for i in scores:\n",
    "    if i > x_h or x_l > i:\n",
    "        count +=1\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
