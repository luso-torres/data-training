{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a812eeab-1bf8-47ad-9df1-700234739296",
   "metadata": {},
   "source": [
    "# Finding interval Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fadf9c23-b672-43f1-b71c-70c07ff48c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 9)\n",
      "(0, 699)\n",
      "Total positive cases in the dataset: 241\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. Carregando data.csv\n",
    "\n",
    "data = pd.read_csv('Data_CSV/data_Breast_Cancer_Wisconsin.csv')\n",
    "# Breast_cancer_data_Suwal_2018.csv\n",
    "# Data_Alzheimer_Diagnosis.csv\n",
    "# data_Breast_Cancer_Wisconsin.csv\n",
    "# data_Mammography.csv\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "data_filled = imputer.fit_transform(data)\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "data = data_filled\n",
    "\n",
    "# Supondo que a última coluna seja a classe\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y[len(y)==-1].shape)\n",
    "\n",
    "# Converta para DataFrame para facilitar a seleção de características\n",
    "# df = pd.DataFrame(X)\n",
    "# corr_matrix = df.corr().abs()\n",
    "\n",
    "# Encontre características altamente correlacionadas\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]  # Limite\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Remova as mesmas características de ambos os conjuntos (treinamento e teste)\n",
    "# X_train_reduced = X_train.drop(to_drop, axis=1)\n",
    "# X_test_reduced = X_test.drop(to_drop, axis=1)\n",
    "\n",
    "# print(f\"Shape of X_train_reduced: {X_train_reduced.shape}\")\n",
    "# print(f\"Shape of X_test_reduced: {X_test_reduced.shape}\")\n",
    "# print(f\"Shape of y_train: {y_train.shape}\")\n",
    "# print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Total positive cases in the dataset: {sum(y == 1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a10fd46b-4bee-43da-876f-5bc01297a6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases in the training set: 217\n",
      "Positive cases in the test set: 24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Adicione essa linha para importar StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# # Normalizar os dados\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# #PCA analysis\n",
    "# pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "print(f\"Positive cases in the training set: {sum(y_train == 1)}\")\n",
    "print(f\"Positive cases in the test set: {sum(y_test == 1)}\")\n",
    "# Inicializar o Bayesiano\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "\n",
    "# Inicializar o LDA com shrinkage para reduzir a colinearidade\n",
    "lda_classifier = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "lda_predictions = lda_classifier.predict(X_test)\n",
    "\n",
    "# Quadrado\n",
    "qda_classifier = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
    "qda_classifier.fit(X_train, y_train)\n",
    "qda_predictions = qda_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42242500-3173-48b9-a0ec-9a7eac90d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier - Confusion Matrix:\n",
      "[[1048   47]\n",
      " [   5   19]]\n",
      "Acurácia por classe:[0.95707763 0.79166667]\n",
      "Acurácia geral: 0.9535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.96      0.98      1095\n",
      "           1       0.29      0.79      0.42        24\n",
      "\n",
      "    accuracy                           0.95      1119\n",
      "   macro avg       0.64      0.87      0.70      1119\n",
      "weighted avg       0.98      0.95      0.96      1119\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis Classifier - Confusion Matrix:\n",
      "[[1077   18]\n",
      " [  11   13]]\n",
      "Acurácia por classe:[0.98356164 0.54166667]\n",
      "Acurácia geral: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.98      0.99      1095\n",
      "           1       0.42      0.54      0.47        24\n",
      "\n",
      "    accuracy                           0.97      1119\n",
      "   macro avg       0.70      0.76      0.73      1119\n",
      "weighted avg       0.98      0.97      0.98      1119\n",
      "\n",
      "\n",
      "Quadratic Discriminant Analysis Classifier - Confusion Matrix:\n",
      "[[1061   34]\n",
      " [   7   17]]\n",
      "Acurácia por classe:[0.96894977 0.70833333]\n",
      "Acurácia geral: 0.9634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.97      0.98      1095\n",
      "           1       0.33      0.71      0.45        24\n",
      "\n",
      "    accuracy                           0.96      1119\n",
      "   macro avg       0.66      0.84      0.72      1119\n",
      "weighted avg       0.98      0.96      0.97      1119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_with_confusion_matrix(name, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(f'\\n{name} Classifier - Confusion Matrix:')\n",
    "        print(cm)\n",
    "\n",
    "    # Acurácia por classe\n",
    "        class_accuracies = cm.diagonal() / cm.sum(axis = 1)\n",
    "        print(f'Acurácia por classe:{class_accuracies}')\n",
    "\n",
    "    # Acurácia geral\n",
    "        overall_accuracy = cm.diagonal().sum() / cm.sum()\n",
    "        print(f'Acurácia geral: {overall_accuracy:.4f}')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_with_confusion_matrix('Naive Bayes',y_test, nb_predictions)\n",
    "evaluate_with_confusion_matrix('Linear Discriminant Analysis', y_test, lda_predictions)\n",
    "evaluate_with_confusion_matrix('Quadratic Discriminant Analysis', y_test, qda_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4dd7f01-0405-4002-bb3c-4063cd4efa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.97587131 0.97944593 0.97944593 0.97676497 0.974084   0.98033959\n",
      " 0.97229669 0.98391421 0.96782842 0.97587131]\n",
      "Média da acurácia: 0.9765862377122432\n",
      "Desvio padrão da acurácia: 0.00431923001737072\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.97676497 0.97319035 0.98302055 0.98123324 0.97229669 0.98302055\n",
      " 0.97765862 0.97855228 0.97944593 0.97497766]\n",
      "Média da acurácia: 0.9780160857908846\n",
      "Desvio padrão da acurácia: 0.003601330058911509\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.95352994 0.96336014 0.95084897 0.9562109  0.95889187 0.94906166\n",
      " 0.95799821 0.95263628 0.96336014 0.95889187]\n",
      "Média da acurácia: 0.9564789991063452\n",
      "Desvio padrão da acurácia: 0.00467869172929703\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "df = pd.read_csv('Data_CSV/data_Mammography.csv')\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "550247ba-fc13-4bfc-b9af-f26b98c12cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.94285714 0.92857143 0.92857143 0.91428571 0.9        0.98571429\n",
      " 0.97142857 0.98571429 0.95714286 0.98571429]\n",
      "Média da acurácia: 0.95\n",
      "Desvio padrão da acurácia: 0.030135747299612853\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.97142857 0.98571429 0.98571429 0.94285714 0.95714286 0.94285714\n",
      " 0.91428571 0.97142857 0.94285714 0.98571429]\n",
      "Média da acurácia: 0.96\n",
      "Desvio padrão da acurácia: 0.02285714285714288\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.94285714 0.91428571 0.97142857 0.92857143 0.95714286 0.97142857\n",
      " 0.98571429 0.98571429 0.95714286 0.98571429]\n",
      "Média da acurácia: 0.96\n",
      "Desvio padrão da acurácia: 0.0237332110369088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('Data_CSV/Breast_cancer_data_Suwal_2018.csv')\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1df25f-0c85-438f-9a06-177ba40a54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.98571429 0.97142857 0.94285714 0.87142857 0.92857143 0.92857143\n",
      " 0.92857143 0.97142857 0.98571429 0.91428571]\n",
      "Média da acurácia: 0.9428571428571428\n",
      "Desvio padrão da acurácia: 0.03440455593940657\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.91428571 0.95714286 0.98571429 0.94285714 0.95714286 0.98571429\n",
      " 0.95714286 0.95714286 0.97142857 0.92857143]\n",
      "Média da acurácia: 0.9557142857142857\n",
      "Desvio padrão da acurácia: 0.02161820850060224\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.97142857 0.94285714 0.95714286 0.97142857 1.         0.98571429\n",
      " 0.97142857 0.95714286 0.97142857 0.97142857]\n",
      "Média da acurácia: 0.97\n",
      "Desvio padrão da acurácia: 0.01491472358415793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('Data_CSV/Data_Alzheimer_Diagnosis.csv')\n",
    "\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bf613a4-b50e-4b71-82db-db8b8e2e1ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Linear\n",
      "Acurácia por repetição: [0.98571429 0.97142857 0.95714286 0.94285714 0.98571429 0.94285714\n",
      " 0.98571429 0.98571429 0.97142857 0.97142857]\n",
      "Média da acurácia: 0.9700000000000001\n",
      "Desvio padrão da acurácia: 0.016225452416572233\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Quadrático\n",
      "Acurácia por repetição: [0.95714286 0.95714286 0.98571429 1.         0.95714286 0.9\n",
      " 0.91428571 0.97142857 0.95714286 0.95714286]\n",
      "Média da acurácia: 0.9557142857142857\n",
      "Desvio padrão da acurácia: 0.02817583274759432\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Acurácia por repetição: [0.95714286 0.97142857 0.92857143 1.         0.94285714 0.98571429\n",
      " 0.97142857 0.97142857 0.95714286 0.94285714]\n",
      "Média da acurácia: 0.9628571428571429\n",
      "Desvio padrão da acurácia: 0.020404081224408142\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('Data_CSV/data_Breast_Cancer_Wisconsin.csv')\n",
    "df = data\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "data_filled = imputer.fit_transform(data)\n",
    "data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "df = data_filled\n",
    "\n",
    "\n",
    "# Supondo que a última coluna seja a variável alvo (classe)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Converter rótulos para valores numéricos, se necessário\n",
    "if y.dtype == 'object':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Criar o modelo Discriminante Linear\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Linear')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "print('\\n\\n\\n\\n Quadrático')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "print('\\n\\n\\n\\n Naive Bayes')\n",
    "# Definir o número de repetições do Monte-Carlo Cross-Validation\n",
    "n_repeats = 10  # Número de iterações\n",
    "test_size = 0.1  # 10% para teste\n",
    "\n",
    "# Armazenar as acurácias\n",
    "scores = []\n",
    "\n",
    "# Loop para realizar as divisões aleatórias\n",
    "for _ in range(n_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Exibir os resultados\n",
    "scores = np.array(scores)\n",
    "print('Acurácia por repetição:', scores)\n",
    "print('Média da acurácia:', scores.mean())\n",
    "print('Desvio padrão da acurácia:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9d04af1-35e1-48dc-8fdf-507f40c85041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955075391587556 0.9578826066251342\n"
     ]
    }
   ],
   "source": [
    "x_l = scores.mean() - scores.std()/n_repeats* z\n",
    "x_h = scores.mean() + scores.std()/n_repeats* z\n",
    "\n",
    "print(x_l,x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f6fc6dd-462d-4256-94f5-6e0349d68dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
